{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('data/DATASET.csv')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "pattern = r'\\b(?:' + '|'.join(stop_words) + r')\\b'\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize_sentence(sentence):\n",
    "#     if isinstance(sentence, str):\n",
    "#       sentence = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(sentence)]\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[please, ignore, previous, negative, rat, app,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pop, get, best, spotify, experience, android,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dear, spotify, get, song, put, playlist, shuf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52697</th>\n",
       "      <td>[yes, best]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>[spotify, heart, feb, heart, music, lyric, lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52699</th>\n",
       "      <td>[try, open, app, wont, open, restart, phone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52700</th>\n",
       "      <td>[good]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>[nice, app, play, music, affordable, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review label\n",
       "0      [great, music, service, audio, high, quality, ...     1\n",
       "1      [please, ignore, previous, negative, rat, app,...     1\n",
       "2      [pop, get, best, spotify, experience, android,...     0\n",
       "3               [really, buggy, terrible, use, recently]     0\n",
       "4      [dear, spotify, get, song, put, playlist, shuf...     0\n",
       "...                                                  ...   ...\n",
       "52697                                        [yes, best]     1\n",
       "52698  [spotify, heart, feb, heart, music, lyric, lan...     1\n",
       "52699  [try, open, app, wont, open, restart, phone, i...     1\n",
       "52700                                             [good]     1\n",
       "52701        [nice, app, play, music, affordable, price]     1\n",
       "\n",
       "[48067 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/DATASET.csv')\n",
    "dataset['Review'] = dataset['Review'].str.lower()\n",
    "dataset = dataset.loc[dataset['Review'].apply(lambda x: isinstance(x, str) and x.isascii())]\n",
    "dataset['label'] = dataset['label'].str.replace('POSITIVE', '1').replace('NEGATIVE', '0')\n",
    "dataset['Review'] = dataset['Review'].str.replace(pattern, '', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[{string.punctuation}]+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(r'\\s+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[0-9]+', '', regex=True)\n",
    "\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : tokenizer.tokenize(sentence))\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='n') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='v') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='a') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='r') for word in sentence])\n",
    "# dataset['Review'] = dataset['Review'].apply(lambda sentence : ' '.join(sentence))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset['Review'], dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rat, app,...\n",
       "2    [pop, get, best, spotify, experience, android,...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, song, put, playlist, shuf...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15392</th>\n",
       "      <th>15393</th>\n",
       "      <th>15394</th>\n",
       "      <th>15395</th>\n",
       "      <th>15396</th>\n",
       "      <th>15397</th>\n",
       "      <th>15398</th>\n",
       "      <th>15399</th>\n",
       "      <th>15400</th>\n",
       "      <th>15401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intricate</td>\n",
       "      <td>kroger</td>\n",
       "      <td>wifi</td>\n",
       "      <td>overarch</td>\n",
       "      <td>countless</td>\n",
       "      <td>hijack</td>\n",
       "      <td>onlynapp</td>\n",
       "      <td>abnormally</td>\n",
       "      <td>wabt</td>\n",
       "      <td>poner</td>\n",
       "      <td>...</td>\n",
       "      <td>rreallly</td>\n",
       "      <td>housework</td>\n",
       "      <td>mont</td>\n",
       "      <td>adios</td>\n",
       "      <td>useage</td>\n",
       "      <td>fork</td>\n",
       "      <td>sth</td>\n",
       "      <td>shirt</td>\n",
       "      <td>tittle</td>\n",
       "      <td>cooperative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 15402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1     2         3          4       5         6           7      \\\n",
       "0  intricate  kroger  wifi  overarch  countless  hijack  onlynapp  abnormally   \n",
       "\n",
       "  8      9      ...     15392      15393 15394  15395   15396 15397 15398  \\\n",
       "0  wabt  poner  ...  rreallly  housework  mont  adios  useage  fork   sth   \n",
       "\n",
       "   15399   15400        15401  \n",
       "0  shirt  tittle  cooperative  \n",
       "\n",
       "[1 rows x 15402 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "for data in X:\n",
    "    all_words.update(data)\n",
    "pd.DataFrame(all_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15402"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Word2Vec(X, vector_size=100, workers=4, min_count=3)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3130541 ,  0.35812715,  0.5448667 ,  0.31108427, -0.8245288 ,\n",
       "       -0.714784  , -0.6085036 ,  1.1736956 , -0.7361906 ,  0.26291087,\n",
       "        0.46788907,  0.08994526, -0.33480304,  1.4417411 , -0.01840737,\n",
       "       -0.57990134, -0.04277718,  0.09661716,  0.20448096,  0.7293754 ,\n",
       "        0.19033672, -0.31082043,  0.10125582,  0.06876709,  0.59068865,\n",
       "        0.47169048,  0.2969946 ,  0.07794444, -0.54570556,  0.51662076,\n",
       "       -0.09132324, -0.5672987 ,  0.7908545 , -0.5944888 ,  0.16975291,\n",
       "        0.5289563 ,  0.64134973, -0.53278804,  0.9544218 , -0.1541316 ,\n",
       "       -1.1372023 ,  0.60789424,  0.3076321 , -0.00434916,  0.21096241,\n",
       "       -0.15450718,  0.28618908,  0.78777206,  1.3554043 , -0.4664213 ,\n",
       "        0.5647667 ,  1.2442716 , -0.20088674, -0.7305257 ,  1.8286911 ,\n",
       "       -0.66403985,  0.34636548,  0.16501369,  0.05450298, -0.17960139,\n",
       "       -0.13708647,  0.76087546, -0.02828667, -0.6221647 , -0.2210206 ,\n",
       "        0.05562142,  0.7218948 ,  0.80009365, -0.33491957, -0.743232  ,\n",
       "        0.3460223 ,  0.40207568, -0.51970124, -0.33258718,  0.6414167 ,\n",
       "        1.0598574 ,  0.5502484 , -0.29247147, -0.109894  , -0.39042348,\n",
       "       -0.931873  ,  0.10830883, -0.3363965 ,  0.5915736 ,  0.11456794,\n",
       "       -0.20628625,  0.4713105 ,  0.5724997 ,  0.35218427,  0.9170591 ,\n",
       "        0.35138565, -0.63844997,  0.01460316,  0.1011434 ,  0.8172888 ,\n",
       "       -0.43479183, -0.14376554, -0.07867149,  0.08500616, -0.65623295],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.wv['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model, vector_size):\n",
    "    # Filter out words that are not in the model vocabulary\n",
    "    words = [word for word in sentence if word in model.wv]\n",
    "    if not words:\n",
    "        return np.zeros(vector_size)  # Return a zero vector if no words in the model\n",
    "    return np.mean([model.wv[word] for word in words], axis=0)\n",
    "\n",
    "X_vectors = np.array([sentence_to_vector(sentence, vectorizer, 100) for sentence in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_vectors, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        error_score=0\n",
    "    )\n",
    "    return model_grid\n",
    "\n",
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')\n",
    "\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'f1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "\n",
    "\n",
    "def display_conf_matrix(y_true, y_pred, Y):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.7s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.1s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   4.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.9s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   6.1s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.1s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  13.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  14.4s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  10.8s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  10.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  11.3s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  12.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.1s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.1s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.1s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  42.1s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  38.4s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  39.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  34.3s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  41.9s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  40.4s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  43.4s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  44.7s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  34.1s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  45.8s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  45.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  35.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.7s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LogisticRegression(C=10.0, solver='liblinear')\n",
      "Best Score -> 0.8617753120665741\n",
      "Best Parameters -> {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best index -> 51\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.8595323292002995\n",
      "recall_score = 0.8529393426560969\n",
      "precision_score = 0.8591312171215727\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "210 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.1, dual=True)\n",
      "Best Score -> 0.8595561719833563\n",
      "Best Parameters -> {'C': 0.1, 'dual': True, 'loss': 'squared_hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best index -> 79\n"
     ]
    }
   ],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 7),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.8584505284180743\n",
      "recall_score = 0.8509489453570687\n",
      "precision_score = 0.8589106303977236\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
