{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('data/DATASET.csv')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "pattern = r'\\b(?:' + '|'.join(stop_words) + r')\\b'\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize_sentence(sentence):\n",
    "#     if isinstance(sentence, str):\n",
    "#       sentence = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(sentence)]\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/DATASET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "dataset['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[please, ignore, previous, negative, rat, app,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pop, get, best, spotify, experience, android,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dear, spotify, get, song, put, playlist, shuf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52697</th>\n",
       "      <td>[yes, best]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>[spotify, heart, feb, heart, music, lyric, lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52699</th>\n",
       "      <td>[try, open, app, wont, open, restart, phone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52700</th>\n",
       "      <td>[good]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>[nice, app, play, music, affordable, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review label\n",
       "0      [great, music, service, audio, high, quality, ...     1\n",
       "1      [please, ignore, previous, negative, rat, app,...     1\n",
       "2      [pop, get, best, spotify, experience, android,...     0\n",
       "3               [really, buggy, terrible, use, recently]     0\n",
       "4      [dear, spotify, get, song, put, playlist, shuf...     0\n",
       "...                                                  ...   ...\n",
       "52697                                        [yes, best]     1\n",
       "52698  [spotify, heart, feb, heart, music, lyric, lan...     1\n",
       "52699  [try, open, app, wont, open, restart, phone, i...     1\n",
       "52700                                             [good]     1\n",
       "52701        [nice, app, play, music, affordable, price]     1\n",
       "\n",
       "[48067 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'] = dataset['Review'].str.lower()\n",
    "dataset = dataset.loc[dataset['Review'].apply(lambda x: isinstance(x, str) and x.isascii())]\n",
    "dataset['label'] = dataset['label'].str.replace('POSITIVE', '1').replace('NEGATIVE', '0')\n",
    "dataset['Review'] = dataset['Review'].str.replace(pattern, '', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[{string.punctuation}]+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(r'\\s+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[0-9]+', '', regex=True)\n",
    "\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : tokenizer.tokenize(sentence))\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='n') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='v') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='a') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='r') for word in sentence])\n",
    "# dataset['Review'] = dataset['Review'].apply(lambda sentence : ' '.join(sentence))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "dataset['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset['Review'], dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rat, app,...\n",
       "2    [pop, get, best, spotify, experience, android,...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, song, put, playlist, shuf...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15392</th>\n",
       "      <th>15393</th>\n",
       "      <th>15394</th>\n",
       "      <th>15395</th>\n",
       "      <th>15396</th>\n",
       "      <th>15397</th>\n",
       "      <th>15398</th>\n",
       "      <th>15399</th>\n",
       "      <th>15400</th>\n",
       "      <th>15401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unjoyable</td>\n",
       "      <td>decentralize</td>\n",
       "      <td>recall</td>\n",
       "      <td>arse</td>\n",
       "      <td>ymusic</td>\n",
       "      <td>detriment</td>\n",
       "      <td>lagy</td>\n",
       "      <td>ablibale</td>\n",
       "      <td>alignment</td>\n",
       "      <td>convinence</td>\n",
       "      <td>...</td>\n",
       "      <td>inexplicably</td>\n",
       "      <td>teddy</td>\n",
       "      <td>shirs</td>\n",
       "      <td>safety</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>turn</td>\n",
       "      <td>brazil</td>\n",
       "      <td>convenient</td>\n",
       "      <td>tivi</td>\n",
       "      <td>equipment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 15402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2     3       4          5     6         7      \\\n",
       "0  unjoyable  decentralize  recall  arse  ymusic  detriment  lagy  ablibale   \n",
       "\n",
       "       8           9      ...         15392  15393  15394   15395    15396  \\\n",
       "0  alignment  convinence  ...  inexplicably  teddy  shirs  safety  alcohol   \n",
       "\n",
       "  15397   15398       15399 15400      15401  \n",
       "0  turn  brazil  convenient  tivi  equipment  \n",
       "\n",
       "[1 rows x 15402 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "for data in X:\n",
    "    all_words.update(data)\n",
    "pd.DataFrame(all_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15402"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Word2Vec(X, vector_size=100, workers=4, min_count=3)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10536017,  0.547176  ,  0.63276494,  0.97949237, -0.61711466,\n",
       "       -1.1126467 , -0.80728453,  0.57098347, -0.6087399 , -0.27667913,\n",
       "        0.60858184,  0.0554064 ,  0.23331912,  1.1489247 ,  0.2811136 ,\n",
       "       -0.5137241 , -0.26404813, -0.20003842, -0.26611796, -0.13732074,\n",
       "        1.372958  ,  0.1413675 ,  0.28054318,  0.02526956,  0.84536356,\n",
       "        0.6693484 ,  0.42038402,  0.33119205, -1.0771605 ,  0.25954878,\n",
       "       -0.06304349, -0.26211056,  0.50501174, -0.70697093,  0.5199337 ,\n",
       "        0.20484515,  0.16485767, -0.50330746,  0.7254726 , -0.42915034,\n",
       "       -0.96152943,  0.5076901 , -0.22321749,  0.35643643,  0.32627803,\n",
       "       -0.3859366 , -0.2873841 ,  0.6395373 ,  1.4981408 , -0.50445503,\n",
       "        0.3656477 ,  1.0397642 , -0.45348457, -0.5295944 ,  1.8134247 ,\n",
       "       -0.58779263,  0.4546917 ,  0.05103473,  0.3394081 , -0.16647433,\n",
       "       -0.10019445,  0.33233833, -0.37137982, -1.0427266 , -0.38052183,\n",
       "        0.04347824,  0.16496907,  0.85731226, -0.21699913, -1.1195182 ,\n",
       "        0.7128414 ,  0.536772  , -0.6034542 , -0.15022524,  0.1956456 ,\n",
       "        1.0333378 ,  0.7476711 ,  0.21646634, -0.05415913, -0.39949358,\n",
       "       -0.80653334,  0.00596805, -0.03891516, -0.00294094, -0.24189797,\n",
       "       -0.20645984, -0.21924666,  0.32259962,  0.13643122,  1.0077611 ,\n",
       "        0.44597587, -1.172042  ,  0.35693714, -0.29074025,  0.12356766,\n",
       "        0.12975526,  0.13961108, -0.04552787,  0.8562195 , -0.440895  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.wv['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model, vector_size):\n",
    "    # Filter out words that are not in the model vocabulary\n",
    "    words = [word for word in sentence if word in model.wv]\n",
    "    if not words:\n",
    "        return np.zeros(vector_size)  # Return a zero vector if no words in the model\n",
    "    return np.mean([model.wv[word] for word in words], axis=0)\n",
    "\n",
    "X_vectors = np.array([sentence_to_vector(sentence, vectorizer, 100) for sentence in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_vectors, Y.astype(np.int8), test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        error_score=0,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    return model_grid\n",
    "\n",
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')\n",
    "\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'accuracy_score = {accuracy_score(y_test, y_pred)}\\nf1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "\n",
    "\n",
    "def display_conf_matrix(y_true, y_pred, Y):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   3.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   3.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   3.2s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   3.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   4.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   3.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   3.6s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   3.3s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   4.1s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   4.3s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   3.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  10.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  11.9s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  11.9s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  12.6s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   6.9s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  13.6s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  10.2s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  12.4s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  12.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  12.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   6.1s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.8s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.1s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  13.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  18.7s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  18.7s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  19.6s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  17.2s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  17.8s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  18.7s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  19.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  18.6s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.3s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  17.3s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  17.8s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  19.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  18.3s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  18.9s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.3s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  18.9s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  18.2s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  37.9s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  46.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  39.7s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  50.2s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.4s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.7s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.8s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  40.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  37.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  44.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  49.8s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   4.4s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   4.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  41.3s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  41.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  38.2s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  37.8s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  50.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.8s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  31.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LogisticRegression(C=10.0, solver='liblinear')\n",
      "Best Score -> 0.860887656033287\n",
      "Best Parameters -> {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best index -> 51\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8607805608720979\n",
      "f1_micro = 0.8607805608720979\n",
      "recall_score = 0.8542500010603689\n",
      "precision_score = 0.8603927603568766\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.4s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.5s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.4s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.5s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.2s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.2s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.2s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.3s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "210 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.0835, dual=True, loss='hinge')\n",
      "Best Score -> 0.8600832177531208\n",
      "Best Parameters -> {'C': 0.0835, 'dual': True, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best index -> 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 7),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8584505284180743\n",
      "f1_micro = 0.8584505284180743\n",
      "recall_score = 0.8514101775623109\n",
      "precision_score = 0.8584256207132889\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_logreg, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linSVC, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class FC_binary(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device -> cuda\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Used device -> {device}')\n",
    "\n",
    "fc_bin = FC_binary(vector_size, hidden_dim, output_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(fc_bin.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_nn = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train_nn = torch.tensor(Y_train.to_numpy(), dtype=torch.float32)\n",
    "Y_test_nn = torch.tensor(Y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_binary(\n",
       "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_bin.to(device=device)\n",
    "# X_train_nn.to(device=device)\n",
    "# X_test_nn.to(device=device)\n",
    "# Y_train_nn.to(device=device)\n",
    "# Y_test_nn.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "train_data = torch.utils.data.TensorDataset(X_train_nn, Y_train_nn)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3609758638698333\n",
      "Epoch 2/100, Loss: 0.33393566252229057\n",
      "Epoch 3/100, Loss: 0.3262814036781215\n",
      "Epoch 4/100, Loss: 0.3216193122351286\n",
      "Epoch 5/100, Loss: 0.31818001140189994\n",
      "Epoch 6/100, Loss: 0.3157427337453655\n",
      "Epoch 7/100, Loss: 0.31395760052296157\n",
      "Epoch 8/100, Loss: 0.31231893205018624\n",
      "Epoch 9/100, Loss: 0.3098111754446931\n",
      "Epoch 10/100, Loss: 0.30919424778291793\n",
      "Epoch 11/100, Loss: 0.30697022595284995\n",
      "Epoch 12/100, Loss: 0.3062589261499039\n",
      "Epoch 13/100, Loss: 0.3047743094580937\n",
      "Epoch 14/100, Loss: 0.30301809007468855\n",
      "Epoch 15/100, Loss: 0.3021037261850451\n",
      "Epoch 16/100, Loss: 0.3015234100350576\n",
      "Epoch 17/100, Loss: 0.29991384376147834\n",
      "Epoch 18/100, Loss: 0.2990611292877976\n",
      "Epoch 19/100, Loss: 0.2983509696616784\n",
      "Epoch 20/100, Loss: 0.2971603934584514\n",
      "Epoch 21/100, Loss: 0.29640815815266086\n",
      "Epoch 22/100, Loss: 0.29533214957024423\n",
      "Epoch 23/100, Loss: 0.2950865461589387\n",
      "Epoch 24/100, Loss: 0.2941744752367091\n",
      "Epoch 25/100, Loss: 0.29330057608494214\n",
      "Epoch 26/100, Loss: 0.2923789269818917\n",
      "Epoch 27/100, Loss: 0.29170443793922374\n",
      "Epoch 28/100, Loss: 0.29062755487879083\n",
      "Epoch 29/100, Loss: 0.2904031019535547\n",
      "Epoch 30/100, Loss: 0.28993189093568417\n",
      "Epoch 31/100, Loss: 0.2888319440576072\n",
      "Epoch 32/100, Loss: 0.2885492488629488\n",
      "Epoch 33/100, Loss: 0.28738471142412186\n",
      "Epoch 34/100, Loss: 0.28700069476913964\n",
      "Epoch 35/100, Loss: 0.286245712152655\n",
      "Epoch 36/100, Loss: 0.28548415674238786\n",
      "Epoch 37/100, Loss: 0.28466247559294516\n",
      "Epoch 38/100, Loss: 0.28498384040163066\n",
      "Epoch 39/100, Loss: 0.2829227813890579\n",
      "Epoch 40/100, Loss: 0.2825761499063516\n",
      "Epoch 41/100, Loss: 0.2820694589757665\n",
      "Epoch 42/100, Loss: 0.2814155083047201\n",
      "Epoch 43/100, Loss: 0.281015644370584\n",
      "Epoch 44/100, Loss: 0.28081514541234925\n",
      "Epoch 45/100, Loss: 0.28036323319971823\n",
      "Epoch 46/100, Loss: 0.27969487657325925\n",
      "Epoch 47/100, Loss: 0.27814281827703236\n",
      "Epoch 48/100, Loss: 0.2775829272161254\n",
      "Epoch 49/100, Loss: 0.27731557253222605\n",
      "Epoch 50/100, Loss: 0.27635039383514115\n",
      "Epoch 51/100, Loss: 0.27571202394120337\n",
      "Epoch 52/100, Loss: 0.2756206946911913\n",
      "Epoch 53/100, Loss: 0.2746872918113418\n",
      "Epoch 54/100, Loss: 0.27446607447757376\n",
      "Epoch 55/100, Loss: 0.27436739421501666\n",
      "Epoch 56/100, Loss: 0.2736817183900218\n",
      "Epoch 57/100, Loss: 0.27300541246344584\n",
      "Epoch 58/100, Loss: 0.2723047050425143\n",
      "Epoch 59/100, Loss: 0.27192456681139193\n",
      "Epoch 60/100, Loss: 0.27116866193268824\n",
      "Epoch 61/100, Loss: 0.2705030732630308\n",
      "Epoch 62/100, Loss: 0.2704780599979986\n",
      "Epoch 63/100, Loss: 0.26945585982598025\n",
      "Epoch 64/100, Loss: 0.2693078532623261\n",
      "Epoch 65/100, Loss: 0.2686452136078342\n",
      "Epoch 66/100, Loss: 0.26832118083019646\n",
      "Epoch 67/100, Loss: 0.26798113102313154\n",
      "Epoch 68/100, Loss: 0.2669038856145864\n",
      "Epoch 69/100, Loss: 0.2673495425491494\n",
      "Epoch 70/100, Loss: 0.26632932477036514\n",
      "Epoch 71/100, Loss: 0.26586959836302126\n",
      "Epoch 72/100, Loss: 0.2657658580257603\n",
      "Epoch 73/100, Loss: 0.2659618576662987\n",
      "Epoch 74/100, Loss: 0.2652188636091502\n",
      "Epoch 75/100, Loss: 0.2654631368736567\n",
      "Epoch 76/100, Loss: 0.26393231982241294\n",
      "Epoch 77/100, Loss: 0.26334968735831654\n",
      "Epoch 78/100, Loss: 0.26292272796978333\n",
      "Epoch 79/100, Loss: 0.26269039914289616\n",
      "Epoch 80/100, Loss: 0.26298071139598694\n",
      "Epoch 81/100, Loss: 0.2620431118030779\n",
      "Epoch 82/100, Loss: 0.2618865420035324\n",
      "Epoch 83/100, Loss: 0.2613961371298162\n",
      "Epoch 84/100, Loss: 0.26122122964001165\n",
      "Epoch 85/100, Loss: 0.26100360076236534\n",
      "Epoch 86/100, Loss: 0.25953302203537937\n",
      "Epoch 87/100, Loss: 0.26011126519518823\n",
      "Epoch 88/100, Loss: 0.2600568869178445\n",
      "Epoch 89/100, Loss: 0.2587165843923481\n",
      "Epoch 90/100, Loss: 0.2582552115752724\n",
      "Epoch 91/100, Loss: 0.2586814264742907\n",
      "Epoch 92/100, Loss: 0.25876461583939186\n",
      "Epoch 93/100, Loss: 0.2576615490753141\n",
      "Epoch 94/100, Loss: 0.2572067670636507\n",
      "Epoch 95/100, Loss: 0.2575824676410435\n",
      "Epoch 96/100, Loss: 0.2574924791220182\n",
      "Epoch 97/100, Loss: 0.2564786908009355\n",
      "Epoch 98/100, Loss: 0.2564194075062461\n",
      "Epoch 99/100, Loss: 0.25616980179443544\n",
      "Epoch 100/100, Loss: 0.2558913583691234\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    fc_bin.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        Y_batch = Y_batch.to(device=device)\n",
    "        \n",
    "        outputs = fc_bin(X_batch).squeeze(1)  # Remove extra dimension\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.86053091\n"
     ]
    }
   ],
   "source": [
    "fc_bin.eval()\n",
    "X_test_nn = X_test_nn.to(device=device)\n",
    "Y_test_nn = Y_test_nn.to(device=device)\n",
    "with torch.no_grad():\n",
    "    outputs = fc_bin(X_test_nn).squeeze(1)\n",
    "    predictions = (outputs > 0.5).float()  # Convert probabilities to 0 or 1\n",
    "    accuracy = (predictions == Y_test_nn).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.8f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
