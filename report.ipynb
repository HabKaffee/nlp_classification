{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('data/DATASET.csv')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "pattern = r'\\b(?:' + '|'.join(stop_words) + r')\\b'\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize_sentence(sentence):\n",
    "#     if isinstance(sentence, str):\n",
    "#       sentence = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(sentence)]\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/DATASET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "dataset['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[please, ignore, previous, negative, rat, app,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pop, get, best, spotify, experience, android,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dear, spotify, get, song, put, playlist, shuf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52697</th>\n",
       "      <td>[yes, best]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>[spotify, heart, feb, heart, music, lyric, lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52699</th>\n",
       "      <td>[try, open, app, wont, open, restart, phone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52700</th>\n",
       "      <td>[good]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>[nice, app, play, music, affordable, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review label\n",
       "0      [great, music, service, audio, high, quality, ...     1\n",
       "1      [please, ignore, previous, negative, rat, app,...     1\n",
       "2      [pop, get, best, spotify, experience, android,...     0\n",
       "3               [really, buggy, terrible, use, recently]     0\n",
       "4      [dear, spotify, get, song, put, playlist, shuf...     0\n",
       "...                                                  ...   ...\n",
       "52697                                        [yes, best]     1\n",
       "52698  [spotify, heart, feb, heart, music, lyric, lan...     1\n",
       "52699  [try, open, app, wont, open, restart, phone, i...     1\n",
       "52700                                             [good]     1\n",
       "52701        [nice, app, play, music, affordable, price]     1\n",
       "\n",
       "[48067 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'] = dataset['Review'].str.lower()\n",
    "dataset = dataset.loc[dataset['Review'].apply(lambda x: isinstance(x, str) and x.isascii())]\n",
    "dataset['label'] = dataset['label'].str.replace('POSITIVE', '1').replace('NEGATIVE', '0')\n",
    "dataset['Review'] = dataset['Review'].str.replace(pattern, '', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[{string.punctuation}]+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(r'\\s+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[0-9]+', '', regex=True)\n",
    "\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : tokenizer.tokenize(sentence))\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='n') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='v') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='a') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='r') for word in sentence])\n",
    "# dataset['Review'] = dataset['Review'].apply(lambda sentence : ' '.join(sentence))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "dataset['label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset['Review'], dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rat, app,...\n",
       "2    [pop, get, best, spotify, experience, android,...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, song, put, playlist, shuf...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15392</th>\n",
       "      <th>15393</th>\n",
       "      <th>15394</th>\n",
       "      <th>15395</th>\n",
       "      <th>15396</th>\n",
       "      <th>15397</th>\n",
       "      <th>15398</th>\n",
       "      <th>15399</th>\n",
       "      <th>15400</th>\n",
       "      <th>15401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easly</td>\n",
       "      <td>ringtones</td>\n",
       "      <td>soundcloud</td>\n",
       "      <td>entire</td>\n",
       "      <td>jonra</td>\n",
       "      <td>reuse</td>\n",
       "      <td>kit</td>\n",
       "      <td>necessary</td>\n",
       "      <td>atta</td>\n",
       "      <td>duo</td>\n",
       "      <td>...</td>\n",
       "      <td>inturps</td>\n",
       "      <td>write</td>\n",
       "      <td>little</td>\n",
       "      <td>spotiy</td>\n",
       "      <td>photograhy</td>\n",
       "      <td>semms</td>\n",
       "      <td>minor</td>\n",
       "      <td>loggin</td>\n",
       "      <td>elevator</td>\n",
       "      <td>hife</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 15402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1           2       3      4      5     6          7     8      \\\n",
       "0  easly  ringtones  soundcloud  entire  jonra  reuse   kit  necessary  atta   \n",
       "\n",
       "  9      ...    15392  15393   15394   15395       15396  15397  15398  \\\n",
       "0   duo  ...  inturps  write  little  spotiy  photograhy  semms  minor   \n",
       "\n",
       "    15399     15400 15401  \n",
       "0  loggin  elevator  hife  \n",
       "\n",
       "[1 rows x 15402 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "for data in X:\n",
    "    all_words.update(data)\n",
    "pd.DataFrame(all_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15402"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Word2Vec(X, vector_size=100, workers=4, min_count=3)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.83649397e-01,  5.64409852e-01, -2.98661646e-04,  6.65295124e-01,\n",
       "       -9.45283175e-01, -8.70343208e-01, -6.10241711e-01,  1.38895798e+00,\n",
       "       -1.18552768e+00, -4.24247354e-01,  3.30048889e-01, -5.69944620e-01,\n",
       "        4.72678952e-02,  1.42438257e+00,  1.00643024e-01, -1.22048998e+00,\n",
       "       -2.78985769e-01, -4.33596671e-01, -2.69910842e-01, -1.01674333e-01,\n",
       "        9.00088906e-01,  1.55116066e-01, -1.72802076e-01, -7.00651288e-01,\n",
       "        1.71467215e-01,  6.32972047e-02, -3.14641371e-02, -1.71145812e-01,\n",
       "       -7.09990263e-01,  3.46030533e-01, -2.04849258e-01, -6.79481506e-01,\n",
       "        6.96264029e-01, -8.51526856e-01,  5.11659086e-01,  3.00256044e-01,\n",
       "        4.80433136e-01, -2.07500979e-01,  7.97649264e-01, -5.90676188e-01,\n",
       "       -1.21296668e+00,  9.44333911e-01,  3.08391690e-01, -1.00826040e-01,\n",
       "        6.53910823e-03, -3.81382376e-01, -1.11747168e-01,  5.95626771e-01,\n",
       "        1.42406356e+00, -8.20564508e-01,  4.52144057e-01,  6.59933269e-01,\n",
       "        5.70992902e-02, -2.17747539e-02,  1.61876345e+00, -2.20791221e-01,\n",
       "        1.12187803e-01,  2.94078916e-01,  4.53843325e-01, -1.71297446e-01,\n",
       "        1.26774788e-01,  3.80127311e-01,  4.20599431e-02, -6.72432482e-01,\n",
       "        2.45953903e-01, -2.37349167e-01, -2.59959549e-01,  8.94959033e-01,\n",
       "       -1.82515464e-03, -1.23880041e+00,  3.72063309e-01,  3.93920958e-01,\n",
       "       -5.98631859e-01, -5.50888658e-01,  3.32321674e-01,  6.79884911e-01,\n",
       "        3.04953456e-01,  1.54089555e-01, -6.13656677e-02, -7.38829970e-01,\n",
       "       -4.39138681e-01,  4.42917615e-01,  3.46689880e-01,  4.49732482e-01,\n",
       "        2.61138682e-03,  2.45287418e-01, -1.49448544e-01,  5.30361950e-01,\n",
       "       -1.85464352e-01,  1.04785335e+00, -1.71017572e-01, -7.08309472e-01,\n",
       "        2.58874387e-01, -2.89913327e-01,  1.70488179e-01, -6.78903639e-01,\n",
       "       -2.62399316e-01,  4.52383399e-01, -1.31418630e-01, -6.27960205e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.wv['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model, vector_size):\n",
    "    # Filter out words that are not in the model vocabulary\n",
    "    words = [word for word in sentence if word in model.wv]\n",
    "    if not words:\n",
    "        return np.zeros(vector_size)  # Return a zero vector if no words in the model\n",
    "    return np.mean([model.wv[word] for word in words], axis=0)\n",
    "\n",
    "X_vectors = np.array([sentence_to_vector(sentence, vectorizer, 100) for sentence in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_vectors, Y.astype(np.int8), test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        error_score=0,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    return model_grid\n",
    "\n",
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')\n",
    "\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'accuracy_score = {accuracy_score(y_test, y_pred)}\\nf1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "\n",
    "\n",
    "def display_conf_matrix(y_true, y_pred, Y):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.1s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   3.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   3.6s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   3.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   8.5s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   9.1s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  10.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  11.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=  11.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   8.8s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   9.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  10.9s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=  12.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   9.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.8s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.2s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  10.8s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.3s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  15.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  14.9s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  16.5s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  15.2s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  15.5s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  13.2s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  14.9s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  15.2s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  14.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  16.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  14.3s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  16.6s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  13.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  21.3s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  15.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  35.2s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  36.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  38.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  39.7s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   5.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   4.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  38.9s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  34.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  38.3s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  36.7s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   5.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  41.3s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  40.5s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  40.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  46.1s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.2s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  40.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  36.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LogisticRegression(C=10.0, solver='liblinear')\n",
      "Best Score -> 0.8625797503467407\n",
      "Best Parameters -> {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best index -> 51\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8604476990929516\n",
      "f1_micro = 0.8604476990929516\n",
      "recall_score = 0.8539102023042524\n",
      "precision_score = 0.860047069428673\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.1s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.6s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.8s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.8s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.9s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   2.1s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.7s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "210 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.0835, dual=True, loss='hinge', max_iter=3000)\n",
      "Best Score -> 0.8605270457697642\n",
      "Best Parameters -> {'C': 0.0835, 'dual': True, 'loss': 'hinge', 'max_iter': 3000, 'penalty': 'l2'}\n",
      "Best index -> 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 7),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8596155446450862\n",
      "f1_micro = 0.8596155446450862\n",
      "recall_score = 0.8521625163826999\n",
      "precision_score = 0.8601003947321246\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_logreg, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linSVC, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class FC_binary(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device -> cuda\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Used device -> {device}')\n",
    "\n",
    "fc_bin = FC_binary(vector_size, hidden_dim, output_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(fc_bin.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_nn = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train_nn = torch.tensor(Y_train.to_numpy(), dtype=torch.float32)\n",
    "Y_test_nn = torch.tensor(Y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC_binary(\n",
       "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_bin.to(device=device)\n",
    "# X_train_nn.to(device=device)\n",
    "# X_test_nn.to(device=device)\n",
    "# Y_train_nn.to(device=device)\n",
    "# Y_test_nn.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "train_data = torch.utils.data.TensorDataset(X_train_nn, Y_train_nn)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3600001414608088\n",
      "Epoch 2/100, Loss: 0.33338368524067574\n",
      "Epoch 3/100, Loss: 0.3256426202637386\n",
      "Epoch 4/100, Loss: 0.3198867575087797\n",
      "Epoch 5/100, Loss: 0.3169833183050579\n",
      "Epoch 6/100, Loss: 0.31400386478087494\n",
      "Epoch 7/100, Loss: 0.3114005365304008\n",
      "Epoch 8/100, Loss: 0.3098420329068018\n",
      "Epoch 9/100, Loss: 0.30809321349028895\n",
      "Epoch 10/100, Loss: 0.3059903290139275\n",
      "Epoch 11/100, Loss: 0.3046648538445834\n",
      "Epoch 12/100, Loss: 0.30311645281161476\n",
      "Epoch 13/100, Loss: 0.3019556013442503\n",
      "Epoch 14/100, Loss: 0.3012231676950852\n",
      "Epoch 15/100, Loss: 0.2988823082136071\n",
      "Epoch 16/100, Loss: 0.29770088034492737\n",
      "Epoch 17/100, Loss: 0.2970621783051643\n",
      "Epoch 18/100, Loss: 0.29590521673502496\n",
      "Epoch 19/100, Loss: 0.29509162016959983\n",
      "Epoch 20/100, Loss: 0.2934783600409579\n",
      "Epoch 21/100, Loss: 0.2927513620564127\n",
      "Epoch 22/100, Loss: 0.2919038990851303\n",
      "Epoch 23/100, Loss: 0.2916222429919423\n",
      "Epoch 24/100, Loss: 0.29057110763405314\n",
      "Epoch 25/100, Loss: 0.2893214897643494\n",
      "Epoch 26/100, Loss: 0.28843906611045483\n",
      "Epoch 27/100, Loss: 0.28831584134801047\n",
      "Epoch 28/100, Loss: 0.28777458326363836\n",
      "Epoch 29/100, Loss: 0.28681320992580217\n",
      "Epoch 30/100, Loss: 0.2859688203619874\n",
      "Epoch 31/100, Loss: 0.2855072875954244\n",
      "Epoch 32/100, Loss: 0.28468154900324694\n",
      "Epoch 33/100, Loss: 0.28491878441428337\n",
      "Epoch 34/100, Loss: 0.2836175573710435\n",
      "Epoch 35/100, Loss: 0.2825316509501323\n",
      "Epoch 36/100, Loss: 0.2822272718653493\n",
      "Epoch 37/100, Loss: 0.2812959471487745\n",
      "Epoch 38/100, Loss: 0.28086404862029424\n",
      "Epoch 39/100, Loss: 0.28020439962025967\n",
      "Epoch 40/100, Loss: 0.2798960705443939\n",
      "Epoch 41/100, Loss: 0.27858115894638974\n",
      "Epoch 42/100, Loss: 0.27907866336729215\n",
      "Epoch 43/100, Loss: 0.2787842101681095\n",
      "Epoch 44/100, Loss: 0.2775788317139474\n",
      "Epoch 45/100, Loss: 0.27662032531258696\n",
      "Epoch 46/100, Loss: 0.275856025014552\n",
      "Epoch 47/100, Loss: 0.2761040515239089\n",
      "Epoch 48/100, Loss: 0.2750937767135113\n",
      "Epoch 49/100, Loss: 0.27419563116441287\n",
      "Epoch 50/100, Loss: 0.27260538985574256\n",
      "Epoch 51/100, Loss: 0.27360032886240265\n",
      "Epoch 52/100, Loss: 0.2731027217133974\n",
      "Epoch 53/100, Loss: 0.27213006608763307\n",
      "Epoch 54/100, Loss: 0.2715826649731149\n",
      "Epoch 55/100, Loss: 0.27096401790310665\n",
      "Epoch 56/100, Loss: 0.2701020849655451\n",
      "Epoch 57/100, Loss: 0.2699678464534014\n",
      "Epoch 58/100, Loss: 0.2693861264937095\n",
      "Epoch 59/100, Loss: 0.2686884346770944\n",
      "Epoch 60/100, Loss: 0.2687992262848204\n",
      "Epoch 61/100, Loss: 0.2674592277291293\n",
      "Epoch 62/100, Loss: 0.2676885070406502\n",
      "Epoch 63/100, Loss: 0.26719720121522655\n",
      "Epoch 64/100, Loss: 0.2663444324323003\n",
      "Epoch 65/100, Loss: 0.2662069084983858\n",
      "Epoch 66/100, Loss: 0.2661139586115687\n",
      "Epoch 67/100, Loss: 0.2647981028392342\n",
      "Epoch 68/100, Loss: 0.2649986600270288\n",
      "Epoch 69/100, Loss: 0.26365846867847464\n",
      "Epoch 70/100, Loss: 0.26379925710047464\n",
      "Epoch 71/100, Loss: 0.26349640992315554\n",
      "Epoch 72/100, Loss: 0.2622674049606287\n",
      "Epoch 73/100, Loss: 0.26271640481270303\n",
      "Epoch 74/100, Loss: 0.2619938282981951\n",
      "Epoch 75/100, Loss: 0.2613181780755996\n",
      "Epoch 76/100, Loss: 0.26220289815445336\n",
      "Epoch 77/100, Loss: 0.26118892791557863\n",
      "Epoch 78/100, Loss: 0.2608121849642777\n",
      "Epoch 79/100, Loss: 0.25984265751138447\n",
      "Epoch 80/100, Loss: 0.2594843294666526\n",
      "Epoch 81/100, Loss: 0.25893968202920753\n",
      "Epoch 82/100, Loss: 0.258199739202976\n",
      "Epoch 83/100, Loss: 0.25857396499843016\n",
      "Epoch 84/100, Loss: 0.25783393958115747\n",
      "Epoch 85/100, Loss: 0.2575829105307914\n",
      "Epoch 86/100, Loss: 0.2579849849173265\n",
      "Epoch 87/100, Loss: 0.2574351442400978\n",
      "Epoch 88/100, Loss: 0.2569511190995561\n",
      "Epoch 89/100, Loss: 0.2569586500135426\n",
      "Epoch 90/100, Loss: 0.2558882529843192\n",
      "Epoch 91/100, Loss: 0.25571187664924094\n",
      "Epoch 92/100, Loss: 0.25533562020366446\n",
      "Epoch 93/100, Loss: 0.2546070695432447\n",
      "Epoch 94/100, Loss: 0.2545710258423859\n",
      "Epoch 95/100, Loss: 0.25476721545289654\n",
      "Epoch 96/100, Loss: 0.2548219046118308\n",
      "Epoch 97/100, Loss: 0.25417226054494957\n",
      "Epoch 98/100, Loss: 0.25306881219809735\n",
      "Epoch 99/100, Loss: 0.25374959502451805\n",
      "Epoch 100/100, Loss: 0.2530059828203975\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    fc_bin.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        Y_batch = Y_batch.to(device=device)\n",
    "        \n",
    "        outputs = fc_bin(X_batch).squeeze(1)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.86319381\n"
     ]
    }
   ],
   "source": [
    "fc_bin.eval()\n",
    "X_test_nn = X_test_nn.to(device=device)\n",
    "Y_test_nn = Y_test_nn.to(device=device)\n",
    "with torch.no_grad():\n",
    "    outputs = fc_bin(X_test_nn).squeeze(1)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "    accuracy = (predictions == Y_test_nn).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.8f}')\n",
    "    \n",
    "torch.save(fc_bin.state_dict(), f'./models/fc_test_{accuracy:.5f}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTextClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=fs) for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        conved = [torch.relu(conv(x)) for conv in self.convs]\n",
    "        pooled = [torch.max(c, dim=2)[0] for c in conved] # Max pooling over dims\n",
    "        \n",
    "        cat = torch.cat(pooled, dim=1)\n",
    "        cat = self.dropout(cat)\n",
    "        \n",
    "        output = self.fc(cat)\n",
    "        \n",
    "        return torch.sigmoid(output).squeeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "num_filters = 100\n",
    "filter_sizes = [3, 4, 5]  # Filter sizes for 3-grams, 4-grams, and 5-grams\n",
    "output_dim = 1 \n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_bin = CNNTextClassifier(vector_size, num_filters, filter_sizes, output_dim, dropout)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(CNN_bin.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTextClassifier(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(1, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(1, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(1, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_bin.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5696\n",
      "Epoch 2/50, Loss: 0.5011\n",
      "Epoch 3/50, Loss: 0.4874\n",
      "Epoch 4/50, Loss: 0.4790\n",
      "Epoch 5/50, Loss: 0.4704\n",
      "Epoch 6/50, Loss: 0.4717\n",
      "Epoch 7/50, Loss: 0.4698\n",
      "Epoch 8/50, Loss: 0.4650\n",
      "Epoch 9/50, Loss: 0.4662\n",
      "Epoch 10/50, Loss: 0.4605\n",
      "Epoch 11/50, Loss: 0.4614\n",
      "Epoch 12/50, Loss: 0.4559\n",
      "Epoch 13/50, Loss: 0.4593\n",
      "Epoch 14/50, Loss: 0.4584\n",
      "Epoch 15/50, Loss: 0.4551\n",
      "Epoch 16/50, Loss: 0.4551\n",
      "Epoch 17/50, Loss: 0.4536\n",
      "Epoch 18/50, Loss: 0.4533\n",
      "Epoch 19/50, Loss: 0.4553\n",
      "Epoch 20/50, Loss: 0.4521\n",
      "Epoch 21/50, Loss: 0.4543\n",
      "Epoch 22/50, Loss: 0.4545\n",
      "Epoch 23/50, Loss: 0.4534\n",
      "Epoch 24/50, Loss: 0.4548\n",
      "Epoch 25/50, Loss: 0.4532\n",
      "Epoch 26/50, Loss: 0.4529\n",
      "Epoch 27/50, Loss: 0.4537\n",
      "Epoch 28/50, Loss: 0.4512\n",
      "Epoch 29/50, Loss: 0.4531\n",
      "Epoch 30/50, Loss: 0.4518\n",
      "Epoch 31/50, Loss: 0.4542\n",
      "Epoch 32/50, Loss: 0.4506\n",
      "Epoch 33/50, Loss: 0.4526\n",
      "Epoch 34/50, Loss: 0.4520\n",
      "Epoch 35/50, Loss: 0.4546\n",
      "Epoch 36/50, Loss: 0.4545\n",
      "Epoch 37/50, Loss: 0.4514\n",
      "Epoch 38/50, Loss: 0.4560\n",
      "Epoch 39/50, Loss: 0.4519\n",
      "Epoch 40/50, Loss: 0.4520\n",
      "Epoch 41/50, Loss: 0.4521\n",
      "Epoch 42/50, Loss: 0.4534\n",
      "Epoch 43/50, Loss: 0.4530\n",
      "Epoch 44/50, Loss: 0.4519\n",
      "Epoch 45/50, Loss: 0.4520\n",
      "Epoch 46/50, Loss: 0.4534\n",
      "Epoch 47/50, Loss: 0.4525\n",
      "Epoch 48/50, Loss: 0.4539\n",
      "Epoch 49/50, Loss: 0.4537\n",
      "Epoch 50/50, Loss: 0.4515\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "train_data = torch.utils.data.TensorDataset(X_train_nn, Y_train_nn)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    CNN_bin.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        \n",
    "        X_batch = X_batch.to(device=device)\n",
    "        Y_batch = Y_batch.to(device=device)\n",
    "        outputs = CNN_bin(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.821753\n"
     ]
    }
   ],
   "source": [
    "CNN_bin.eval()\n",
    "X_test_nn = X_test_nn.to(device=device)\n",
    "Y_test_nn = Y_test_nn.to(device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = CNN_bin(X_test_nn)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "    accuracy = (predictions == Y_test_nn).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.6f}')\n",
    "    \n",
    "torch.save(fc_bin.state_dict(), f'./models/cnn_test_{accuracy:.6f}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
