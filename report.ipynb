{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('data/DATASET.csv')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "pattern = r'\\b(?:' + '|'.join(stop_words) + r')\\b'\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize_sentence(sentence):\n",
    "#     if isinstance(sentence, str):\n",
    "#       sentence = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(sentence)]\n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[please, ignore, previous, negative, rat, app,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pop, get, best, spotify, experience, android,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dear, spotify, get, song, put, playlist, shuf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52697</th>\n",
       "      <td>[yes, best]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52698</th>\n",
       "      <td>[spotify, heart, feb, heart, music, lyric, lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52699</th>\n",
       "      <td>[try, open, app, wont, open, restart, phone, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52700</th>\n",
       "      <td>[good]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52701</th>\n",
       "      <td>[nice, app, play, music, affordable, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review label\n",
       "0      [great, music, service, audio, high, quality, ...     1\n",
       "1      [please, ignore, previous, negative, rat, app,...     1\n",
       "2      [pop, get, best, spotify, experience, android,...     0\n",
       "3               [really, buggy, terrible, use, recently]     0\n",
       "4      [dear, spotify, get, song, put, playlist, shuf...     0\n",
       "...                                                  ...   ...\n",
       "52697                                        [yes, best]     1\n",
       "52698  [spotify, heart, feb, heart, music, lyric, lan...     1\n",
       "52699  [try, open, app, wont, open, restart, phone, i...     1\n",
       "52700                                             [good]     1\n",
       "52701        [nice, app, play, music, affordable, price]     1\n",
       "\n",
       "[48067 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/DATASET.csv')\n",
    "dataset['Review'] = dataset['Review'].str.lower()\n",
    "dataset = dataset.loc[dataset['Review'].apply(lambda x: isinstance(x, str) and x.isascii())]\n",
    "dataset['label'] = dataset['label'].str.replace('POSITIVE', '1').replace('NEGATIVE', '0')\n",
    "dataset['Review'] = dataset['Review'].str.replace(pattern, '', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[{string.punctuation}]+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(r'\\s+', ' ', regex=True)\n",
    "dataset['Review'] = dataset['Review'].str.replace(f'[0-9]+', '', regex=True)\n",
    "\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : tokenizer.tokenize(sentence))\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='n') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='v') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='a') for word in sentence])\n",
    "dataset['Review'] = dataset['Review'].apply(lambda sentence : [lemmatizer.lemmatize(word, pos='r') for word in sentence])\n",
    "# dataset['Review'] = dataset['Review'].apply(lambda sentence : ' '.join(sentence))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset['Review'], dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rat, app,...\n",
       "2    [pop, get, best, spotify, experience, android,...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, song, put, playlist, shuf...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15392</th>\n",
       "      <th>15393</th>\n",
       "      <th>15394</th>\n",
       "      <th>15395</th>\n",
       "      <th>15396</th>\n",
       "      <th>15397</th>\n",
       "      <th>15398</th>\n",
       "      <th>15399</th>\n",
       "      <th>15400</th>\n",
       "      <th>15401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intricate</td>\n",
       "      <td>kroger</td>\n",
       "      <td>wifi</td>\n",
       "      <td>overarch</td>\n",
       "      <td>countless</td>\n",
       "      <td>hijack</td>\n",
       "      <td>onlynapp</td>\n",
       "      <td>abnormally</td>\n",
       "      <td>wabt</td>\n",
       "      <td>poner</td>\n",
       "      <td>...</td>\n",
       "      <td>rreallly</td>\n",
       "      <td>housework</td>\n",
       "      <td>mont</td>\n",
       "      <td>adios</td>\n",
       "      <td>useage</td>\n",
       "      <td>fork</td>\n",
       "      <td>sth</td>\n",
       "      <td>shirt</td>\n",
       "      <td>tittle</td>\n",
       "      <td>cooperative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 15402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1     2         3          4       5         6           7      \\\n",
       "0  intricate  kroger  wifi  overarch  countless  hijack  onlynapp  abnormally   \n",
       "\n",
       "  8      9      ...     15392      15393 15394  15395   15396 15397 15398  \\\n",
       "0  wabt  poner  ...  rreallly  housework  mont  adios  useage  fork   sth   \n",
       "\n",
       "   15399   15400        15401  \n",
       "0  shirt  tittle  cooperative  \n",
       "\n",
       "[1 rows x 15402 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set()\n",
    "for data in X:\n",
    "    all_words.update(data)\n",
    "pd.DataFrame(all_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15402"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Word2Vec(X, vector_size=100, workers=4, min_count=3)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3130541 ,  0.35812715,  0.5448667 ,  0.31108427, -0.8245288 ,\n",
       "       -0.714784  , -0.6085036 ,  1.1736956 , -0.7361906 ,  0.26291087,\n",
       "        0.46788907,  0.08994526, -0.33480304,  1.4417411 , -0.01840737,\n",
       "       -0.57990134, -0.04277718,  0.09661716,  0.20448096,  0.7293754 ,\n",
       "        0.19033672, -0.31082043,  0.10125582,  0.06876709,  0.59068865,\n",
       "        0.47169048,  0.2969946 ,  0.07794444, -0.54570556,  0.51662076,\n",
       "       -0.09132324, -0.5672987 ,  0.7908545 , -0.5944888 ,  0.16975291,\n",
       "        0.5289563 ,  0.64134973, -0.53278804,  0.9544218 , -0.1541316 ,\n",
       "       -1.1372023 ,  0.60789424,  0.3076321 , -0.00434916,  0.21096241,\n",
       "       -0.15450718,  0.28618908,  0.78777206,  1.3554043 , -0.4664213 ,\n",
       "        0.5647667 ,  1.2442716 , -0.20088674, -0.7305257 ,  1.8286911 ,\n",
       "       -0.66403985,  0.34636548,  0.16501369,  0.05450298, -0.17960139,\n",
       "       -0.13708647,  0.76087546, -0.02828667, -0.6221647 , -0.2210206 ,\n",
       "        0.05562142,  0.7218948 ,  0.80009365, -0.33491957, -0.743232  ,\n",
       "        0.3460223 ,  0.40207568, -0.51970124, -0.33258718,  0.6414167 ,\n",
       "        1.0598574 ,  0.5502484 , -0.29247147, -0.109894  , -0.39042348,\n",
       "       -0.931873  ,  0.10830883, -0.3363965 ,  0.5915736 ,  0.11456794,\n",
       "       -0.20628625,  0.4713105 ,  0.5724997 ,  0.35218427,  0.9170591 ,\n",
       "        0.35138565, -0.63844997,  0.01460316,  0.1011434 ,  0.8172888 ,\n",
       "       -0.43479183, -0.14376554, -0.07867149,  0.08500616, -0.65623295],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.wv['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model, vector_size):\n",
    "    # Filter out words that are not in the model vocabulary\n",
    "    words = [word for word in sentence if word in model.wv]\n",
    "    if not words:\n",
    "        return np.zeros(vector_size)  # Return a zero vector if no words in the model\n",
    "    return np.mean([model.wv[word] for word in words], axis=0)\n",
    "\n",
    "X_vectors = np.array([sentence_to_vector(sentence, vectorizer, 100) for sentence in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_vectors, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        error_score=0\n",
    "    )\n",
    "    return model_grid\n",
    "\n",
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')\n",
    "\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'f1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "\n",
    "\n",
    "def display_conf_matrix(y_true, y_pred, Y):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .....C=0.01, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END ....C=0.01, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ......C=0.1, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.6s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END .....C=0.1, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.7s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   7.1s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l1, solver=liblinear; total time=   4.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=100, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.7s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.9s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   6.1s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ......C=0.5, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ..C=0.5, max_iter=500, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.1s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.0s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   6.5s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l1, solver=liblinear; total time=   7.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END .....C=0.5, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.4s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END .C=0.5, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  13.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  14.4s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  10.8s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l1, solver=liblinear; total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  10.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  11.3s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l1, solver=liblinear; total time=  12.0s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.8s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......C=1.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ..C=1.0, max_iter=500, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.1s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.1s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.1s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END .....C=1.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.8s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END .C=1.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  42.1s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  38.4s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  39.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  34.3s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l1, solver=liblinear; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=10.0, max_iter=100, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=100, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  41.9s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  40.4s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  43.4s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  44.7s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l1, solver=liblinear; total time=  34.1s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .....C=10.0, max_iter=500, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END .C=10.0, max_iter=500, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  45.8s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  45.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.9s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  35.1s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear; total time=  39.7s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END ....C=10.0, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LogisticRegression(C=10.0, solver='liblinear')\n",
      "Best Score -> 0.8617753120665741\n",
      "Best Parameters -> {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best index -> 51\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.8595323292002995\n",
      "recall_score = 0.8529393426560969\n",
      "precision_score = 0.8591312171215727\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.2s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0175, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0175, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.034, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.6s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.8s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   0.9s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.1s\n",
      "[CV] END C=0.067, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0835, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.2s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.0835, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.7s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; total time=   0.3s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.4s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; total time=   0.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; total time=   0.0s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.4s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n",
      "[CV] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "210 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/habkaffee/programming/nlp/nlp_classification/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.1, dual=True)\n",
      "Best Score -> 0.8595561719833563\n",
      "Best Parameters -> {'C': 0.1, 'dual': True, 'loss': 'squared_hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best index -> 79\n"
     ]
    }
   ],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 7),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.8584505284180743\n",
      "recall_score = 0.8509489453570687\n",
      "precision_score = 0.8589106303977236\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_logreg, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linSVC, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
